#!/usr/bin/env node

/**
 * Gerador de Documenta√ß√£o
 * 
 * Gera documenta√ß√£o completa do sistema baseada no c√≥digo
 * e configura√ß√µes atuais.
 */

const fs = require('fs');
const path = require('path');
const chalk = require('chalk');

class DocumentationGenerator {
  constructor() {
    this.projectRoot = path.join(__dirname, '..');
    this.docsDir = path.join(this.projectRoot, 'docs');
  }

  async run() {
    console.log(chalk.cyan('\nüìö Gerador de Documenta√ß√£o'));
    console.log(chalk.cyan('‚ïê'.repeat(35)));
    console.log(chalk.gray('Gerando documenta√ß√£o completa do sistema\n'));

    try {
      await this.createDocsDirectory();
      await this.generateAPIDocumentation();
      await this.generateArchitectureDoc();
      await this.generateConfigurationDoc();
      await this.generateTroubleshootingDoc();
      await this.generateContributingDoc();
      await this.updateMainReadme();
      await this.showCompletionMessage();
    } catch (error) {
      console.error(chalk.red('\n‚ùå Erro durante gera√ß√£o:'), error.message);
      process.exit(1);
    }
  }

  async createDocsDirectory() {
    if (!fs.existsSync(this.docsDir)) {
      fs.mkdirSync(this.docsDir, { recursive: true });
      console.log(chalk.green('‚úÖ Diret√≥rio docs/ criado'));
    }
  }

  async generateAPIDocumentation() {
    console.log(chalk.yellow('üìñ Gerando documenta√ß√£o da API...'));

    const apiDoc = `# üì° Documenta√ß√£o da API

## Vis√£o Geral

O sistema de scraping de eventos oferece uma API interna para intera√ß√£o com os dados coletados e configura√ß√µes do sistema.

## M√≥dulos Principais

### 1. Scrapers

#### EventbriteScraper
\`\`\`javascript
const scraper = new EventbriteScraper();
await scraper.scrapeEvents('Ji-Paran√°', 'RO');
\`\`\`

**M√©todos:**
- \`scrapeEvents(city, state)\` - Coleta eventos de uma cidade
- \`scrapeEventDetails(eventUrl)\` - Coleta detalhes de um evento espec√≠fico
- \`validateEvent(eventData)\` - Valida dados do evento

#### SymplaScraper
\`\`\`javascript
const scraper = new SymplaScraper();
await scraper.scrapeEvents('Ji-Paran√°', 'RO');
\`\`\`

**M√©todos:**
- \`scrapeEvents(city, state)\` - Coleta eventos de uma cidade
- \`scrapeEventDetails(eventUrl)\` - Coleta detalhes de um evento espec√≠fico
- \`validateEvent(eventData)\` - Valida dados do evento

### 2. Storage

#### SupabaseStorage
\`\`\`javascript
const storage = new SupabaseStorage();
await storage.saveEvent(eventData);
\`\`\`

**M√©todos:**
- \`saveEvent(eventData)\` - Salva evento no banco
- \`getEvents(filters)\` - Busca eventos com filtros
- \`updateEvent(id, data)\` - Atualiza evento existente
- \`deleteEvent(id)\` - Remove evento

### 3. Processors

#### EventProcessor
\`\`\`javascript
const processor = new EventProcessor();
const processedData = await processor.process(rawEventData);
\`\`\`

**M√©todos:**
- \`process(rawData)\` - Processa dados brutos
- \`normalize(data)\` - Normaliza formato dos dados
- \`validate(data)\` - Valida dados processados
- \`enrich(data)\` - Enriquece dados com informa√ß√µes adicionais

## Estrutura de Dados

### Evento
\`\`\`javascript
{
  id: 'string',
  title: 'string',
  description: 'string',
  date: 'ISO 8601 string',
  location: {
    venue: 'string',
    address: 'string',
    city: 'string',
    state: 'string'
  },
  price: {
    min: 'number',
    max: 'number',
    currency: 'string'
  },
  category: 'string',
  source: 'eventbrite|sympla',
  url: 'string',
  image: 'string',
  organizer: 'string',
  created_at: 'ISO 8601 string',
  updated_at: 'ISO 8601 string'
}
\`\`\`

## Rate Limiting

O sistema implementa rate limiting respeitoso:
- Eventbrite: 2-4 segundos entre requisi√ß√µes
- Sympla: 2-3.5 segundos entre requisi√ß√µes
- Configur√°vel via vari√°veis de ambiente

## Tratamento de Erros

Todos os m√©todos podem lan√ßar as seguintes exce√ß√µes:
- \`ScrapingError\` - Erro durante scraping
- \`ValidationError\` - Erro de valida√ß√£o de dados
- \`StorageError\` - Erro de armazenamento
- \`NetworkError\` - Erro de rede/conectividade
`;

    fs.writeFileSync(path.join(this.docsDir, 'API.md'), apiDoc);
    console.log(chalk.green('‚úÖ Documenta√ß√£o da API criada'));
  }

  async generateArchitectureDoc() {
    console.log(chalk.yellow('üèóÔ∏è Gerando documenta√ß√£o de arquitetura...'));
    
    const archDoc = `# üèóÔ∏è Arquitetura do Sistema

## Vis√£o Geral

O sistema de scraping de eventos √© constru√≠do com uma arquitetura modular e escal√°vel, focada em confiabilidade e manutenibilidade.

## Componentes Principais

### 1. Interface Layer
- **CLI Interface**: Menu interativo para opera√ß√µes manuais
- **Web Interface**: Dashboard para visualiza√ß√£o (futuro)
- **Cron Jobs**: Execu√ß√£o automatizada

### 2. Core Application
- **Main Controller**: Orquestra todas as opera√ß√µes
- **Configuration Manager**: Gerencia configura√ß√µes
- **Logger**: Sistema de logging estruturado
- **Error Handler**: Tratamento centralizado de erros

### 3. Scrapers Layer
- **Base Scraper**: Classe abstrata com funcionalidades comuns
- **Eventbrite Scraper**: Implementa√ß√£o espec√≠fica para Eventbrite
- **Sympla Scraper**: Implementa√ß√£o espec√≠fica para Sympla
- **Generic Scraper**: Para sites n√£o espec√≠ficos

### 4. Processing Layer
- **Data Validator**: Valida√ß√£o de dados coletados
- **Data Normalizer**: Padroniza√ß√£o de formatos
- **Data Enricher**: Adi√ß√£o de informa√ß√µes complementares
- **Duplicate Detector**: Identifica√ß√£o de eventos duplicados

### 5. Storage Layer
- **Supabase Client**: Interface com banco de dados
- **File Storage**: Armazenamento de arquivos locais
- **Cache Manager**: Sistema de cache para performance

### 6. Reports Layer
- **Report Generator**: Gera√ß√£o de relat√≥rios
- **Chart Generator**: Cria√ß√£o de gr√°ficos
- **Export Manager**: Exporta√ß√£o em diferentes formatos

## Fluxo de Dados

### 1. Coleta de Dados
\`\`\`
User Input ‚Üí Scraper Selection ‚Üí Target Configuration ‚Üí Data Extraction
\`\`\`

### 2. Processamento
\`\`\`
Raw Data ‚Üí Validation ‚Üí Normalization ‚Üí Enrichment ‚Üí Duplicate Check
\`\`\`

### 3. Armazenamento
\`\`\`
Processed Data ‚Üí Database Storage ‚Üí File Backup ‚Üí Cache Update
\`\`\`

### 4. Relat√≥rios
\`\`\`
Stored Data ‚Üí Analysis ‚Üí Report Generation ‚Üí Export ‚Üí Notification
\`\`\`
`;

    fs.writeFileSync(path.join(this.docsDir, 'ARCHITECTURE.md'), archDoc);
    console.log(chalk.green('‚úÖ Documenta√ß√£o de arquitetura criada'));
  }

  async generateConfigurationDoc() {
    console.log(chalk.yellow('‚öôÔ∏è Gerando documenta√ß√£o de configura√ß√£o...'));
    
    const configDoc = `# ‚öôÔ∏è Guia de Configura√ß√£o

## Vari√°veis de Ambiente

### üóÑÔ∏è Banco de Dados
\`\`\`bash
SUPABASE_URL=https://seu-projeto.supabase.co
SUPABASE_ANON_KEY=sua_chave_anonima_aqui
\`\`\`

### üï∑Ô∏è Configura√ß√µes de Scraping
\`\`\`bash
SCRAPING_MAX_RETRIES=3
SCRAPING_TIMEOUT=30000
SCRAPING_MAX_CONCURRENCY=2
SCRAPING_USER_AGENT="EventScraper/1.0"
\`\`\`

### ‚è±Ô∏è Rate Limiting
\`\`\`bash
EVENTBRITE_RATE_LIMIT=2000
SYMPLA_RATE_LIMIT=2500
\`\`\`

### üìù Logging
\`\`\`bash
LOG_LEVEL=info
LOG_TO_FILE=true
LOG_MAX_FILES=5
LOG_MAX_SIZE=5242880
\`\`\`

### üéØ Configura√ß√µes Regionais
\`\`\`bash
PRIMARY_REGION="Ji-Paran√°"
PRIMARY_STATE="RO"
NEARBY_CITIES="Ariquemes,Cacoal,Rolim de Moura,Vilhena"
\`\`\`
`;

    fs.writeFileSync(path.join(this.docsDir, 'CONFIGURATION.md'), configDoc);
    console.log(chalk.green('‚úÖ Documenta√ß√£o de configura√ß√£o criada'));
  }

  async generateTroubleshootingDoc() {
    console.log(chalk.yellow('üîß Gerando guia de troubleshooting...'));
    
    const troubleshootingDoc = `# üîß Guia de Troubleshooting

## Problemas Comuns e Solu√ß√µes

### 1. üö´ Erro de Conex√£o com Supabase

**Sintomas:**
- Erro "Failed to connect to Supabase"
- Timeout em opera√ß√µes de banco
- Dados n√£o s√£o salvos

**Solu√ß√µes:**
\`\`\`bash
# Verificar credenciais
echo $SUPABASE_URL
echo $SUPABASE_ANON_KEY

# Testar conectividade
curl -I $SUPABASE_URL

# Verificar configura√ß√£o
npm run check
\`\`\`

### 2. üï∑Ô∏è Falhas no Scraping

**Sintomas:**
- "No events found" consistentemente
- Timeout em requisi√ß√µes
- Elementos n√£o encontrados

**Solu√ß√µes:**
\`\`\`bash
# Aumentar rate limiting
EVENTBRITE_RATE_LIMIT=5000
SYMPLA_RATE_LIMIT=4000

# Executar em modo debug
LOG_LEVEL=debug npm start

# Testar com headless desabilitado
PUPPETEER_HEADLESS=false npm start
\`\`\`

### 3. üíæ Problemas de Mem√≥ria

**Sintomas:**
- "JavaScript heap out of memory"
- Sistema lento ou travando
- Processo sendo morto pelo OS

**Solu√ß√µes:**
\`\`\`bash
# Aumentar limite de mem√≥ria Node.js
node --max-old-space-size=2048 index.js

# Reduzir concorr√™ncia
SCRAPING_MAX_CONCURRENCY=1

# Monitorar uso de mem√≥ria
npm run monitor
\`\`\`

## Comandos de Diagn√≥stico

### Verifica√ß√£o Completa do Sistema
\`\`\`bash
npm run check
\`\`\`

### Limpeza do Sistema
\`\`\`bash
npm run clean
npm run reset
\`\`\`
`;

    fs.writeFileSync(path.join(this.docsDir, 'TROUBLESHOOTING.md'), troubleshootingDoc);
    console.log(chalk.green('‚úÖ Guia de troubleshooting criado'));
  }

  async generateContributingDoc() {
    console.log(chalk.yellow('ü§ù Gerando guia de contribui√ß√£o...'));
    
    const contributingDoc = `# ü§ù Guia de Contribui√ß√£o

## Bem-vindo!

Obrigado pelo interesse em contribuir com o projeto de scraping de eventos do Brasil!

## üöÄ Come√ßando

### Pr√©-requisitos
- Node.js 18+
- Git
- Conta no GitHub
- Conhecimento b√°sico de JavaScript/Node.js

### Setup do Ambiente
\`\`\`bash
# 1. Fork o reposit√≥rio no GitHub

# 2. Clone seu fork
git clone https://github.com/seu-usuario/eventos-scraper-brasil.git
cd eventos-scraper-brasil

# 3. Instale depend√™ncias
npm install

# 4. Configure o ambiente
npm run setup

# 5. Execute os testes
npm test

# 6. Inicie o sistema
npm start
\`\`\`

## üìù Padr√µes de C√≥digo

### Estilo de C√≥digo
- Use ESLint (configura√ß√£o inclu√≠da)
- Indenta√ß√£o: 2 espa√ßos
- Aspas simples para strings
- Ponto e v√≠rgula obrigat√≥rio

### Conven√ß√µes de Nomenclatura
- **Arquivos:** kebab-case (\`event-scraper.js\`)
- **Classes:** PascalCase (\`EventScraper\`)
- **Fun√ß√µes/Vari√°veis:** camelCase (\`scrapeEvents\`)
- **Constantes:** UPPER_SNAKE_CASE (\`MAX_RETRIES\`)

## üß™ Testes

### Executar Testes
\`\`\`bash
npm test
npm run test:coverage
npm run test:watch
\`\`\`

## üè∑Ô∏è Conven√ß√µes de Commit

Use [Conventional Commits](https://conventionalcommits.org/):

- \`feat:\` nova funcionalidade
- \`fix:\` corre√ß√£o de bug
- \`docs:\` mudan√ßas na documenta√ß√£o
- \`test:\` adi√ß√£o ou corre√ß√£o de testes
- \`chore:\` tarefas de manuten√ß√£o
`;

    fs.writeFileSync(path.join(this.docsDir, 'CONTRIBUTING.md'), contributingDoc);
    console.log(chalk.green('‚úÖ Guia de contribui√ß√£o criado'));
  }

  async updateMainReadme() {
    console.log(chalk.yellow('üìÑ Atualizando README principal...'));

    const mainReadme = `# üéâ Sistema de Scraping de Eventos - Brasil

[![Node.js](https://img.shields.io/badge/Node.js-18+-green.svg)](https://nodejs.org/)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Tests](https://img.shields.io/badge/Tests-Passing-brightgreen.svg)](tests/)

Sistema automatizado para coleta e organiza√ß√£o de eventos no Brasil, com foco especial na regi√£o de Ji-Paran√°/RO e cidades pr√≥ximas.

## üöÄ Funcionalidades

- ‚úÖ **Scraping Automatizado** - Coleta eventos do Eventbrite e Sympla
- ‚úÖ **Armazenamento Inteligente** - Banco de dados Supabase com deduplica√ß√£o
- ‚úÖ **Relat√≥rios Detalhados** - An√°lises e estat√≠sticas em PDF/CSV
- ‚úÖ **Monitoramento Cont√≠nuo** - Acompanha mudan√ßas na estrutura dos sites
- ‚úÖ **Interface Amig√°vel** - Menu interativo para todas as opera√ß√µes
- ‚úÖ **Rate Limiting Respeitoso** - Respeita os termos de servi√ßo dos sites
- ‚úÖ **Logs Estruturados** - Sistema completo de logging e auditoria
- ‚úÖ **Deploy Simplificado** - Scripts automatizados para produ√ß√£o

## üìã Pr√©-requisitos

- Node.js 18 ou superior
- Conta no [Supabase](https://supabase.com) (gratuita)
- 1GB de RAM dispon√≠vel
- Conex√£o est√°vel com a internet

## ‚ö° Instala√ß√£o R√°pida

\`\`\`bash
# 1. Clone o reposit√≥rio
git clone https://github.com/seu-usuario/eventos-scraper-brasil.git
cd eventos-scraper-brasil

# 2. Instale as depend√™ncias
npm install

# 3. Configure o sistema (interativo)
npm run setup

# 4. Verifique a instala√ß√£o
npm run check

# 5. Inicie o sistema
npm start
\`\`\`

## üìñ Documenta√ß√£o Completa

- üìö [**Guia de Instala√ß√£o**](INSTALL.md) - Instru√ß√µes detalhadas
- üèóÔ∏è [**Arquitetura**](docs/ARCHITECTURE.md) - Como o sistema funciona
- üì° [**API**](docs/API.md) - Documenta√ß√£o t√©cnica
- ‚öôÔ∏è [**Configura√ß√£o**](docs/CONFIGURATION.md) - Todas as op√ß√µes
- üîß [**Troubleshooting**](docs/TROUBLESHOOTING.md) - Solu√ß√£o de problemas
- üöÄ [**Deploy**](DEPLOYMENT.md) - Produ√ß√£o e PM2
- ü§ù [**Contribui√ß√£o**](docs/CONTRIBUTING.md) - Como ajudar

## üéØ Uso B√°sico

### Menu Interativo
\`\`\`bash
npm start
\`\`\`

### Comandos Diretos
\`\`\`bash
npm run check    # Verificar sistema
npm run scrape   # Executar scraping
npm run report   # Gerar relat√≥rio
npm run monitor  # Monitorar estrutura
npm run clean    # Limpar dados antigos
\`\`\`

## üöÄ Deploy em Produ√ß√£o

### Com PM2 (Recomendado)
\`\`\`bash
npm run deploy:prepare
npm install -g pm2
pm2 start ecosystem.config.js
pm2 monit
\`\`\`

## üß™ Testes

\`\`\`bash
npm test                    # Todos os testes
npm run test:coverage       # Testes com coverage
npm run test:integration    # Testes de integra√ß√£o
\`\`\`

## ü§ù Contribuindo

Contribui√ß√µes s√£o muito bem-vindas! Veja o [guia de contribui√ß√£o](docs/CONTRIBUTING.md) para come√ßar.

## üìú Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

---

**Feito com ‚ù§Ô∏è para a comunidade de Ji-Paran√°/RO e regi√£o**

‚≠ê Se este projeto te ajudou, considere dar uma estrela no GitHub!
`;

    fs.writeFileSync(path.join(this.projectRoot, 'README.md'), mainReadme);
    console.log(chalk.green('‚úÖ README principal atualizado'));
  }

  async showCompletionMessage() {
    console.log(chalk.cyan('üìö Documenta√ß√£o Completa Gerada!'));
    console.log(chalk.cyan('‚ïê'.repeat(40)));
    
    console.log(chalk.green('\n‚úÖ Documentos criados:'));
    console.log(chalk.gray('  ‚Ä¢ docs/API.md - Documenta√ß√£o da API'));
    console.log(chalk.gray('  ‚Ä¢ docs/ARCHITECTURE.md - Arquitetura do sistema'));
    console.log(chalk.gray('  ‚Ä¢ docs/CONFIGURATION.md - Guia de configura√ß√£o'));
    console.log(chalk.gray('  ‚Ä¢ docs/TROUBLESHOOTING.md - Solu√ß√£o de problemas'));
    console.log(chalk.gray('  ‚Ä¢ docs/CONTRIBUTING.md - Guia de contribui√ß√£o'));
    console.log(chalk.gray('  ‚Ä¢ README.md - Documenta√ß√£o principal atualizada'));

    console.log(chalk.green('\nüìö Sistema totalmente documentado!'));
    console.log('');
  }
}

// Executar se chamado diretamente
if (require.main === module) {
  const generator = new DocumentationGenerator();
  generator.run().catch(error => {
    console.error(chalk.red('Erro durante gera√ß√£o da documenta√ß√£o:'), error);
    process.exit(1);
  });
}

module.exports = { DocumentationGenerator };